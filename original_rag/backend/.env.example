# === Agentic RAG Environment Variables ===

# === Application ===
DEBUG=false

# === API ===
API_HOST=0.0.0.0
API_PORT=8001
CORS_ORIGINS=http://localhost:3000,http://localhost:5173

# === LLM Provider ===
# Options: openai, ollama, gemini
LLM_PROVIDER=ollama

# OpenAI (if LLM_PROVIDER=openai)
OPENAI_API_KEY=sk-...
OPENAI_MODEL=gpt-4o-mini

# Ollama (if LLM_PROVIDER=ollama)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.1:8b

# Ollama Performance Tuning (reduces latency by 50%+)
# KV cache quantization: f16 (default), q8_0 (faster), q4_0 (fastest)
OLLAMA_KV_CACHE_TYPE=q8_0
# Context window size
OLLAMA_NUM_CTX=4096
# Flash attention (requires compatible GPU)
OLLAMA_FLASH_ATTENTION=true

# Gemini (if LLM_PROVIDER=gemini)
GOOGLE_API_KEY=...
GEMINI_MODEL=gemini-1.5-flash

# === Embeddings ===
# Options: fastembed, openai, ollama (fastembed recommended - fast, no external service)
EMBEDDING_PROVIDER=fastembed
FASTEMBED_MODEL=BAAI/bge-small-en-v1.5
OPENAI_EMBEDDING_MODEL=text-embedding-3-small
OLLAMA_EMBEDDING_MODEL=nomic-embed-text

# === Vector Store ===
# Options: chroma (recommended)
VECTOR_PROVIDER=chroma
CHROMA_PATH=./data/chroma
COLLECTION_NAME=knowledge_base

# === Memory ===
# Options: sqlite, redis
MEMORY_BACKEND=sqlite
REDIS_URL=redis://localhost:6379
MEMORY_DB_PATH=./data/memory.db

# === Chunking ===
CHUNK_SIZE=1000
CHUNK_OVERLAP=200

# === Retrieval ===
TOP_K=5
RERANK_TOP_N=3
RELEVANCE_THRESHOLD=0.7

# === Self-Correction ===
MAX_RETRIES=2
HALLUCINATION_THRESHOLD=0.8

# === Paths ===
DATA_DIR=./data
UPLOADS_DIR=./data/uploads
